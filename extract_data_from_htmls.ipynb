{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOBYpSAqEUXaqR2lvp9QWLI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#connect to google drive and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5brP9IPQbPch","executionInfo":{"status":"ok","timestamp":1745919215173,"user_tz":-120,"elapsed":20144,"user":{"displayName":"Fabio Santamaría","userId":"16998571430491345217"}},"outputId":"cd867a0b-dd71-4bed-c2cc-e0e6eb8fd9b6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"DRs9zPQ2bJFm","executionInfo":{"status":"ok","timestamp":1745919215789,"user_tz":-120,"elapsed":608,"user":{"displayName":"Fabio Santamaría","userId":"16998571430491345217"}}},"outputs":[],"source":["import os\n","import json\n","import csv\n","from bs4 import BeautifulSoup\n","from bs4.element import NavigableString\n","\n","def extract_full_property_info_css_selector(html_content, page_url=None):\n","    \"\"\"\n","    Extracts property information using CSS selectors to find the\n","    utag_data script tag, and also extracts details from other sections\n","    like 'Características básicas', 'Equipamiento', and 'Certificado energético'.\n","    It also extracts the canonical URL from the <link rel=\"canonical\"> tag.\n","    Includes fallback to string search for utag_data.\n","\n","    Args:\n","        html_content: HTML content string.\n","        page_url: Original page URL (optional, will be overridden if canonical URL is found).\n","\n","    Returns:\n","        Dictionary of property information.\n","    \"\"\"\n","    soup = BeautifulSoup(html_content, 'html.parser')\n","    property_info = {\n","        'characteristics': {},\n","        'ad_info': {},\n","        'details': {'basic_features': [], 'equipment': [], 'energy_certificate': {}},\n","        'source_url': page_url # Initialize with provided page_url, will be updated if canonical is found\n","    }\n","\n","    # 0. Extract canonical URL\n","    canonical_link_tag = soup.find('link', rel='canonical')\n","    if canonical_link_tag and canonical_link_tag.get('href'):\n","        property_info['source_url'] = canonical_link_tag['href']\n","    else:\n","        print(\"Canonical URL link not found in HTML.\") # Debugging line\n","\n","\n","    # 1. Try CSS selector to find script tag (more direct)\n","    script_tags_css = soup.select('script') # Select all script tags\n","\n","    utag_data_script_tag = None\n","    for tag in script_tags_css:\n","        if tag.string and \"var utag_data\" in tag.string:\n","            utag_data_script_tag = tag\n","            break # Stop once found\n","\n","\n","    if not utag_data_script_tag: # 2. Fallback to original string search if CSS fails\n","        utag_data_script_tag = soup.find('script', string=lambda text: isinstance(text, NavigableString) and \"utag_data\" in text)\n","        if not utag_data_script_tag: # Even simpler fallback\n","             utag_data_script_tag = soup.find('script', string=lambda text:  \"utag_data\" in text if text else False)\n","\n","\n","    if utag_data_script_tag:\n","        script_content = utag_data_script_tag.string\n","        if script_content:\n","            start_index = script_content.find('var utag_data = ')\n","            if start_index != -1:\n","                start_index += len('var utag_data = ')\n","                end_index = script_content.find(';', start_index)\n","                if end_index != -1:\n","                    try:\n","                        utag_data_json_str = script_content[start_index:end_index]\n","                        utag_data = json.loads(utag_data_json_str)\n","\n","                        if \"ad\" in utag_data and isinstance(utag_data[\"ad\"], dict) and \"characteristics\" in utag_data[\"ad\"]:\n","                            characteristics = utag_data[\"ad\"][\"characteristics\"]\n","                            property_info['characteristics'] = {k: characteristics[k] for k in characteristics}\n","\n","                        if \"ad\" in utag_data and isinstance(utag_data[\"ad\"], dict):\n","                            ad_data = utag_data[\"ad\"]\n","                            property_info['ad_info']['id'] = ad_data.get(\"id\", None)\n","                            property_info['ad_info']['operation'] = ad_data.get(\"operation\", None)\n","                            property_info['ad_info']['typology'] = ad_data.get(\"typology\", None)\n","                            property_info['ad_info']['price'] = ad_data.get(\"price\", None)\n","                            property_info['ad_info']['builtType'] = ad_data.get(\"builtType\", None)\n","\n","                            if \"address\" in ad_data and isinstance(ad_data[\"address\"], dict):\n","                                address_data = ad_data[\"address\"]\n","                                location_parts = []\n","                                if address_data.get(\"locationLevel\") == \"6\":\n","                                    if address_data.get(\"municipalityId\"):\n","                                        location_parts.append(address_data.get(\"municipalityId\").split('-')[-1])\n","                                    if address_data.get(\"provinceId\"):\n","                                        location_parts.append(address_data.get(\"provinceId\").split('-')[-1])\n","                                property_info['ad_info']['location'] = \", \".join(location_parts) if location_parts else None\n","\n","                            if \"condition\" in ad_data and isinstance(ad_data[\"condition\"], dict):\n","                                property_info['ad_info']['condition'] = {k: ad_data[\"condition\"][k] for k in ad_data[\"condition\"]}\n","\n","                            if \"media\" in ad_data and isinstance(ad_data[\"media\"], dict):\n","                                property_info['ad_info']['media'] = {k: ad_data[\"media\"][k] for k in ad_data[\"media\"]}\n","\n","                            if \"owner\" in ad_data and isinstance(ad_data[\"owner\"], dict):\n","                                property_info['ad_info']['owner'] = {k: ad_data[\"owner\"][k] for k in ad_data[\"owner\"]}\n","\n","                            if \"agency\" in ad_data and isinstance(ad_data[\"agency\"], dict):\n","                                property_info['ad_info']['agency'] = {k: ad_data[\"agency\"][k] for k in ad_data[\"agency\"]}\n","\n","\n","                    except json.JSONDecodeError:\n","                        print(\"Error decoding JSON from script content (utag_data).\")\n","\n","    # Extract details from other sections\n","    details_property_div = soup.find('div', class_='details-property')\n","    if details_property_div:\n","        # Características básicas\n","        basic_features_div = details_property_div.find('div', class_='details-property-feature-one')\n","        if basic_features_div:\n","            basic_features_list = basic_features_div.find('div', class_='details-property_features').find_all('li')\n","            property_info['details']['basic_features'] = [li.text.strip() for li in basic_features_list]\n","\n","        # Equipamiento\n","        equipment_div = details_property_div.find('div', class_='details-property-feature-two')\n","        if equipment_div:\n","            equipment_lists = equipment_div.find_all('div', class_='details-property_features')\n","            if len(equipment_lists) > 0: # Equipamiento list is usually the first\n","                equipment_list = equipment_lists[0].find_all('li')\n","                property_info['details']['equipment'] = [li.text.strip() for li in equipment_list]\n","\n","            if len(equipment_lists) > 1: # Certificado energético list is usually the second\n","                energy_certificate_list = equipment_lists[1].find_all('li')\n","                for li in energy_certificate_list:\n","                    span_elements = li.find_all('span')\n","                    if len(span_elements) == 2:\n","                        label = span_elements[0].text.strip()\n","                        rating_class = span_elements[1].get('class')\n","                        rating = None\n","                        if rating_class:\n","                            rating_parts = rating_class[0].split('-') # class is like icon-energy-c-c\n","                            if len(rating_parts) >= 3:\n","                                rating = rating_parts[2].upper() # Get the rating letter, e.g., 'C'\n","                        if \"Consumo\" in label:\n","                            property_info['details']['energy_certificate']['consumption_rating'] = rating\n","                        elif \"Emisiones\" in label:\n","                            property_info['details']['energy_certificate']['emissions_rating'] = rating\n","    return property_info\n","\n","def flatten_property_info(property_info):\n","    \"\"\"\n","    Flattens the nested property information dictionary into a single-level dictionary\n","    suitable for CSV writing.\n","    \"\"\"\n","    flattened_info = {}\n","    for section, data in property_info.items():\n","        if isinstance(data, dict):\n","            for key, value in data.items():\n","                if isinstance(value, list): # Flatten lists, e.g., basic_features, equipment\n","                    for i, item in enumerate(value):\n","                        flattened_info[f'{section}_{key}_{i}'] = item\n","                elif isinstance(value, dict): # Flatten nested dictionaries, e.g., energy_certificate\n","                     for nested_key, nested_value in value.items():\n","                         flattened_info[f'{section}_{key}_{nested_key}'] = nested_value\n","                else:\n","                    flattened_info[f'{section}_{key}'] = value\n","        elif isinstance(data, list): # Flatten top-level lists if any\n","            for i, item in enumerate(data):\n","                flattened_info[f'{section}_{i}'] = item\n","        else: # For simple key-value pairs at the top level (e.g., source_url)\n","            flattened_info[section] = data\n","    return flattened_info\n","\n"]},{"cell_type":"code","source":["import json\n","import csv\n","from bs4 import BeautifulSoup\n","from bs4.element import NavigableString\n","\n","def extract_detailed_property_features(html_content, page_url=None):\n","    \"\"\"\n","    Extracts detailed property features from HTML content, focusing on\n","    'Características básicas', 'Equipamiento', and 'Certificado energético'\n","    within the 'details-property' div. Extracts data into a dictionary\n","    suitable for CSV conversion, handling variable lists and missing values.\n","\n","    Args:\n","        html_content: HTML content string.\n","        page_url: Original page URL (optional, included in output).\n","\n","    Returns:\n","        Dictionary of detailed property features, flattened for CSV.\n","    \"\"\"\n","    soup = BeautifulSoup(html_content, 'html.parser')\n","\n","    # 0. Extract canonical URL\n","    canonical_link_tag = soup.find('link', rel='canonical')\n","    if canonical_link_tag and canonical_link_tag.get('href'):\n","        page_url = canonical_link_tag['href']\n","        print(page_url)\n","    else:\n","        print(\"Canonical URL link not found in HTML.\") # Debugging line\n","\n","\n","    property_features = {\n","        'source_url': page_url,\n","        'property_type': None,\n","        'floors': None,\n","        'size_built_sqm': None,\n","        'size_useful_sqm': None,\n","        'rooms': None,\n","        'bathrooms': None,\n","        'plot_size_sqm': None,\n","        'terrace': 'No',  # Default values, will be updated if found\n","        'balcony': 'No',\n","        'parking': 'No',\n","        'condition': None,\n","        'built_in_wardrobes': 'No',\n","        'storage_room': 'No',\n","        'orientation': None,\n","        'built_year': None,\n","        'heating_type': None,\n","        'garden': 'No', # Default values for Equipamiento\n","        'swimming_pool': 'No',\n","        'energy_consumption_rating': None, # Energy certificate\n","        'energy_emissions_rating': None,\n","        'price': None, # Price\n","        'location': None, # Location\n","        'ad_update_date': None, # Ad update date\n","        'advertiser_name': None # Advertiser name\n","    }\n","\n","    # Extract Price\n","    price_span = soup.find('span', class_='info-data-price')\n","    if price_span:\n","        price_text = price_span.text.strip()\n","        property_features['price'] = price_text\n","\n","    # Extract Location\n","    location_span = soup.find('span', class_='main-info__title-minor')\n","    if location_span:\n","        location_text = location_span.text.strip()\n","        property_features['location'] = location_text\n","\n","    # Extract Ad Update Date\n","    date_update_section = soup.find('section', class_='details-box date-update-block')\n","    if date_update_section:\n","        date_update_p = date_update_section.find('p', class_='date-update-text')\n","        if date_update_p:\n","            date_update_text = date_update_p.text.strip()\n","            property_features['ad_update_date'] = date_update_text\n","\n","    # Extract Advertiser Name\n","    advertiser_container = soup.find('div', class_='advertiser-name-container')\n","    if advertiser_container:\n","        advertiser_link = advertiser_container.find('a', class_='about-advertiser-name')\n","        if advertiser_link:\n","            advertiser_name = advertiser_link.text.strip()\n","            property_features['advertiser_name'] = advertiser_name\n","    else: # If 'advertiser-name-container' not found, try 'particular'\n","        particular_span = soup.find('span', class_='particular')\n","        if particular_span:\n","            # Extract text directly within 'particular' span, ignoring child tags\n","            advertiser_name_parts = []\n","            for child in particular_span.contents:\n","                if isinstance(child, NavigableString): # Check if it's text and not a tag\n","                    advertiser_name_parts.append(child.strip())\n","            advertiser_name = ' '.join(advertiser_name_parts).strip() # Join parts and strip again\n","            if advertiser_name: # Only assign if not empty\n","                 property_features['advertiser_name'] = f\"PARTICULAR: {advertiser_name}\"\n","\n","    # Try to extract size from info-features div first (before details-property)\n","    info_features_div = soup.find('div', class_='info-features')\n","    if info_features_div:\n","        size_span = info_features_div.find('span') # Size is usually the first span\n","        if size_span:\n","            size_text = size_span.text.strip()\n","            if 'm²' in size_text:\n","                property_features['size_built_sqm'] = size_text.split(' m²')[0].replace('.','').replace(',','.')\n","\n","    details_property_div = soup.find('div', class_='details-property')\n","    if not details_property_div:\n","        return property_features # Return defaults if main section is not found\n","\n","    # Características básicas\n","    basic_features_div = details_property_div.find('div', class_='details-property-feature-one')\n","    if basic_features_div:\n","        basic_features_list = basic_features_div.find('div', class_='details-property_features').find_all('li')\n","        for item in basic_features_list:\n","            text = item.text.strip()\n","            if 'Casa o chalet independiente' in text:\n","                property_features['property_type'] = 'Casa o chalet independiente' # Or just 'Chalet'/'Casa' if you prefer\n","            elif 'planta' in text and 'plantas' not in text: # Modified to catch \"1 planta\"\n","                property_features['floors'] = text.split(' ')[0] # Extract number of floors\n","            elif 'plantas' in text:\n","                property_features['floors'] = text.split(' ')[0] # Extract number of floors\n","            elif 'm² construidos' in text and 'm² útiles' in text: # Handle combined case\n","                parts = text.split(',') # Split by comma to separate construidos and utiles\n","                for part in parts:\n","                    if 'm² útiles' in part:\n","                        property_features['size_useful_sqm'] = part.split(' m²')[0].replace(' m² útiles','').strip().replace('.','').replace(',','.')\n","                    elif 'm² construidos' in part:\n","                        property_features['size_built_sqm'] = part.split(' m²')[0].replace(' m² construidos','').strip().replace('.','').replace(',','.')\n","            elif 'habitaciones' in text:\n","                property_features['rooms'] = text.split(' ')[0] # Extract number of rooms\n","            elif 'baño' in text and 'baños' not in text: # Modified to catch \"1 baño\"\n","                property_features['bathrooms'] = text.split(' ')[0] # Extract number of bathrooms\n","            elif 'baños' in text:\n","                property_features['bathrooms'] = text.split(' ')[0] # Extract number of bathrooms\n","            elif 'Parcela de' in text and 'm²' in text:\n","                property_features['plot_size_sqm'] = text.split(' ')[2].replace('m²','').replace('.','').replace(',','.') # Extract plot size\n","            elif 'Terraza' in text:\n","                property_features['terrace'] = 'Yes'\n","            elif 'balcón' in text or 'Balcón' in text: # Handle both cases\n","                property_features['balcony'] = 'Yes'\n","            elif 'garaje' in text:\n","                property_features['parking'] = 'Yes'\n","            elif 'Segunda mano' in text:\n","                property_features['condition'] = text.replace('Segunda mano/','').replace('/buen estado','') # e.g., \"buen estado\"\n","            elif 'Armarios empotrados' in text:\n","                property_features['built_in_wardrobes'] = 'Yes'\n","            elif 'Trastero' in text:\n","                property_features['storage_room'] = 'Yes'\n","            elif 'Orientación' in text:\n","                property_features['orientation'] = text.replace('Orientación ','') # e.g., \"sur\"\n","            elif 'Construido en' in text:\n","                property_features['built_year'] = text.split(' ')[-1] # Extract year\n","            elif 'No dispone de calefacción' in text: # Handle \"No dispone de calefacción\" first\n","                property_features['heating_type'] = 'No dispone de calefacción'\n","            elif 'Calefacción individual' in text: # Then handle \"Calefacción individual\"\n","                property_features['heating_type'] = 'Calefacción individual'\n","\n","\n","\n","    # Equipamiento\n","    equipment_div = details_property_div.find('div', class_='details-property-feature-two')\n","    if equipment_div:\n","        equipment_lists = equipment_div.find_all('div', class_='details-property_features')\n","        if len(equipment_lists) > 0: # Equipamiento list is usually the first\n","            equipment_list = equipment_lists[0].find_all('li')\n","            for item in equipment_list:\n","                text = item.text.strip()\n","                if 'Jardín' in text:\n","                    property_features['garden'] = 'Yes'\n","                elif 'Piscina' in text:\n","                    property_features['swimming_pool'] = 'Yes'\n","                # Add more equipment features here if needed, following the same pattern\n","\n","        if len(equipment_lists) > 1: # Certificado energético list is usually the second\n","            energy_certificate_list = equipment_lists[1].find_all('li')\n","            for li in energy_certificate_list:\n","                span_elements = li.find_all('span')\n","                if len(span_elements) == 2:\n","                    label = span_elements[0].text.strip()\n","                    rating_class = span_elements[1].get('class')\n","                    rating_value = span_elements[1].text.strip() # Extract text value as well (e.g., \"10 kWh/m² año\")\n","                    rating = None\n","                    if rating_class:\n","                        rating_parts = rating_class[0].split('-') # class is like icon-energy-c-b\n","                        if len(rating_parts) >= 3:\n","                            rating = rating_parts[2].upper() # Get the rating letter, e.g., 'B'\n","                    if \"Consumo\" in label:\n","                        property_features['energy_consumption_rating'] = f\"{rating} ({rating_value})\" if rating and rating_value else rating # Include value if available\n","                    elif \"Emisiones\" in label:\n","                        property_features['energy_emissions_rating'] = rating\n","\n","\n","    return property_features"],"metadata":{"id":"BJyzUJng3vXA","executionInfo":{"status":"ok","timestamp":1745919215802,"user_tz":-120,"elapsed":54,"user":{"displayName":"Fabio Santamaría","userId":"16998571430491345217"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def process_html_files_to_csv(folder_path, csv_file_path=\"output.csv\"):\n","    \"\"\"\n","    Processes all HTML files in a folder, extracts property information, flattens it,\n","    and writes it to a CSV file.\n","\n","    Args:\n","        folder_path: Path to the folder containing HTML files.\n","        csv_file_path: Path to the output CSV file (default: \"output.csv\").\n","    \"\"\"\n","    all_property_data = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".html\"):\n","            html_file_path = os.path.join(folder_path, filename)\n","            try:\n","                with open(html_file_path, 'r', encoding='utf-8') as f:\n","                    html_content = f.read()\n","                #property_info = extract_full_property_info_css_selector(html_content, page_url=None) # Or extract URL from filename if relevant\n","                property_info = extract_detailed_property_features(html_content, page_url=None)\n","                #flattened_info = flatten_property_info(property_info)\n","                all_property_data.append(property_info)\n","            except FileNotFoundError:\n","                print(f\"Error: HTML file not found: {html_file_path}\")\n","            except Exception as e:\n","                print(f\"Error processing HTML file: {html_file_path} - {e}\")\n","\n","    if not all_property_data:\n","        print(\"No data extracted. CSV not created.\")\n","        return\n","\n","    # Determine all possible header fields (union of keys from all dictionaries)\n","    csv_headers = set()\n","    for data_dict in all_property_data:\n","        csv_headers.update(data_dict.keys())\n","    csv_headers = sorted(list(csv_headers)) # Sort headers for consistent order\n","\n","    # Before opening the file, ensure the directory exists\n","    os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)\n","\n","    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n","        csv_writer = csv.DictWriter(csvfile, fieldnames=csv_headers)\n","        csv_writer.writeheader()\n","        for data_dict in all_property_data:\n","            csv_writer.writerow(data_dict)\n","\n","    print(f\"Data from HTML files in '{folder_path}' written to '{csv_file_path}'\")\n","\n","base_folder = \"/content/drive/MyDrive/Comprar casa/extraccion idealista\"\n","\n","process_html_files_to_csv(f\"{base_folder}/raw_htmls/pontevedra/\",\n","                          csv_file_path=f\"{base_folder}/output/pontevedra/20250425.csv\")\n","\n","print(\"CSV file 'property_data.csv' created (or updated).\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfERl08E3zoo","executionInfo":{"status":"ok","timestamp":1745919221669,"user_tz":-120,"elapsed":5866,"user":{"displayName":"Fabio Santamaría","userId":"16998571430491345217"}},"outputId":"d32c6b90-4a3f-4ba8-b7e0-f85cb3088eff"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["https://www.idealista.com/inmueble/108010682/\n","https://www.idealista.com/inmueble/108003454/\n","https://www.idealista.com/inmueble/107996591/\n","https://www.idealista.com/inmueble/107994855/\n","https://www.idealista.com/inmueble/107984536/\n","https://www.idealista.com/inmueble/107594263/\n","https://www.idealista.com/inmueble/104240077/\n","Data from HTML files in '/content/drive/MyDrive/Comprar casa/extraccion idealista/raw_htmls/pontevedra/' written to '/content/drive/MyDrive/Comprar casa/extraccion idealista/output/pontevedra/20250425.csv'\n","CSV file 'property_data.csv' created (or updated).\n"]}]}]}